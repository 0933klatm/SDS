---
author: Sebastian Barfort
title: "Social Data Science"
subtitle: Tidy Data, Data Manipulation & Functions
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  beamer_presentation:
    keep_tex: no
    theme: metropolis
    latex_engine: xelatex
    slide_level: 2
    incremental: no
    fig_width: 7
    fig_height: 6
    fig_caption: false
    includes:
      in_header: header.tex
fontsize: 10pt
classoption: compress
---

```{r Setup, include=FALSE, results='hide', warning=FALSE}
hook_output = knitr::knit_hooks$get('output')
knitr::knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(
              dev= "pdf",
               fig.width=4.25,
               fig.height=2.5,
               fig.show="hold",
               fig.lp="fig:",
               fig.align = "center",
               dpi = 300,
               cache=TRUE,
               par=TRUE,
               echo=TRUE,
               message=FALSE,
               warning=FALSE)
```

## Intro 

> "Herein lies the dirty secret about most data scientists' work – it's more data munging than deep learning. The best minds of my generation are deleting commas from log files, and that makes me sad. A Ph.D. is a terrible thing to waste."

[Source](http://adage.com/article/digitalnext/dear-madison-avenue-set-data-scientists-free/298676/)

## Data janitor

![](figures/janitor.png)

[Source](http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html)

## Raw versus processed data

### Raw data 

The original source of the data

Often hard to use directly for data analysis

You should *never* process your original data

### Processed data

Data that is ready for analysis

Data manipulation involves going from *raw* to *processed* data. 

This can include merging, subsetting, transforming, etc. 

*All* steps that take you from raw to processed data should be scripted

## Today 

Introduce some tricks for working (efficiently) with data 

Introduce concept and tools for working with tidy data (`tidyr`)

Manipulate tidy data using `dplyr`

Iterate over elements using functions (`purrr`)

String processing (`stringr`, regular expressions)

## Workflow

![](figures/workflow.jpg)

---

\LARGE The Pipe

## Digression: The pipe

![](figures/pipe.png)

## The pipe operator

The pipe operator `%>%` (RStudio has keyboard shortcuts, learn to use them!) let's you write sequences instead of nested functions

`x %>% f(y)` -> `f(x,y)`
    
`x %>% f(z, .)` -> `f(z, x)`

Read `%>%` as "then". First do this, *then* do this, etc...

It's implemented in `R` by a [Danish econometrician](https://twitter.com/stefanbache)

All the packages you will learn today work with the pipe. 

## Intuition 

\centering
![](figures/romain.jpg)

[source](http://www.slideshare.net/romainfrancois)

---

\LARGE Tidy data

## `tidyr`  

### Tidy data: observations are in the rows, variables are in the columns

`tidyr`: take your messy data and turn it into a tidy format

Advantages of tidy data:

- Consistency 
- Allows you to spend more time on your analysis 
- Speed

## Tidy data

![](figures/tidy-1.png)

## Functions in `tidyr`

- `gather`: Reshape from wide to long
- `spread`: Reshape from long to wide 
- `separate`: Split a variable into multiple variables.

(Also more complicated functions such as `nest` for nested data frames, but we won't go into detail with those here)

## Read data

```{r, message = FALSE, tidy=FALSE}
library("readr")
gh.link = "https://raw.githubusercontent.com/"
user.repo = "hadley/tidyr/"
branch = "master/"
link = "vignettes/pew.csv"
data.link = paste0(gh.link, user.repo, branch, link)
df = read_csv(data.link)
```

## Pew data 

### First five columns

```{r, echo = FALSE}
knitr::kable(df[1:3, 1:5])
```

**Question 1**: What variables are in this dataset?

**Question 2**: How does a tidy version of this data look like?

## The `gather` function

**Problem**: Column names are not names of a variable, but *values* of a variable.

**Objective**: Reshaping wide format to long format

To tidy such data, we need to **gather** the non-variable columns into a two-column key-value pair

## `gather`

Three parameters

1. Set of columns that represent values, not variables.
2. Name of the variable whose values form the column names (`key`).
3. The name of the variable whose values are spread over the cells (`value`. 

```{r}
library("tidyr")
args(gather)
```

## `gather` Pew Data

```{r}
df.gather = df %>% 
  gather(key = income, 
         value = frequency, 
         -religion)
```

## 

```{r, echo = FALSE}
knitr::kable(df.gather[1:5, ])
```

## Alternatives

This

```{r, eval = FALSE}
df %>% 
  gather(key = income, 
         value = frequency, 
         2:11)
```

returns the same as 

```{r, eval = FALSE}
df %>% 
  gather(key = income, 
         value = frequency, 
         -religion)
```

## More complicated example

### Billboard data

```{r}
library("readr")
gh.link = "https://raw.githubusercontent.com/"
user.repo = "hadley/tidyr/"
branch = "master/"
link = "vignettes/billboard.csv"
data.link = paste0(gh.link, user.repo, branch, link)
df = read_csv(data.link)
```

## Billboard is a mess

`df[1:5, 1:5]`

```{r, echo = FALSE}
knitr::kable(df[1:5, 1:5])
```

## 

`df[1:5, 6:10]`

```{r, echo = FALSE}
knitr::kable(df[1:5, 6:10])
```

**Question**: what are the variables here? 

## Tidying the Billboard data

To tidy this dataset, we first gather together all the `wk` columns. The column names give the week and the values are the ranks:

```{r}
billboard2 = df %>% 
  gather(key = week, 
         value = rank, wk1:wk76, 
         na.rm = TRUE)
```

## 

Not displaying the `track` column

```{r, echo = FALSE}
knitr::kable(billboard2[1:5, -3])
```

Are we done? 

## Data cleaning

Let's turn the week into a numeric variable and create a proper date column

```{r}
library("dplyr")
billboard3 = billboard2 %>%
  mutate(
    week = extract_numeric(week),
    date = as.Date(date.entered) + 7 * (week - 1)) %>%
  select(-date.entered) %>% 
  arrange(artist, track, week)
```

What functions from `tidyr` did we use here? 

## 

```{r, echo = FALSE}
knitr::kable(billboard3[1:5, 1:5])
```

## WHO example

After gathering columns, the key column is sometimes a combination of multiple underlying variable names. 

```{r, message = FALSE}
library("readr")
gh.link = "https://raw.githubusercontent.com/"
user.repo = "hadley/tidyr/"
branch = "master/"
link = "vignettes/tb.csv"
data.link = paste0(gh.link, user.repo, branch, link)
df = read_csv(data.link)
```

## 

```{r, echo = FALSE}
knitr::kable(df[1:5, 1:8])
```

**Question**: what are the variables here?

## Answer

The dataset comes from the World Health Organisation, and records the \alert{counts} of confirmed tuberculosis cases by \alert{country}, \alert{year}, and \alert{demographic group}. The demographic groups are broken down by \alert{sex} (m, f) and \alert{age} (0-14, 15-25, 25-34, 35-44, 45-54, 55-64, unknown).

## Gathering the non-variable columns

```{r}
tb2 = df %>% 
  gather(demo, n, -iso2, -year, na.rm = TRUE)
```

## 

```{r, echo = FALSE}
knitr::kable(tb2[1:5, 1:4])
```

Is this dataset tidy?

## Separating the `demo` variable

`separate` makes it easy to split a variable into multiple variables. You can either pass it a regular expression to split on or a vector of character positions. In this case we want to split after the first character.

```{r}
tb3 = tb2 %>% 
  separate(demo, c("sex", "age"), 1)
```

##

```{r, echo = FALSE}
knitr::kable(tb3[1:5, 1:5])
```

## Reshaping from long to wide format

There are times when we are required to turn long formatted data into wide formatted data. The `spread` function spreads a key-value pair across multiple columns.

## `spread` in action

```{r}
tb3.wide = tb3 %>% spread(age, n)
```

## 

```{r, echo = FALSE}
knitr::kable(tb3.wide[1:5, 1:8])
```

---

\LARGE Data Manipulation

## The Split-Apply-Combine approach 

Once you have your data stored in tidy form, you can easily apply a \alert{split-apply-combine strategy}, where you break up a big problem into manageable pieces, opereate on each piece independently and then put the pieces back together

\centering
![](figures/split.png)

## Split-Apply-Combine

\centering
![](figures/split-apply-combine.png)

## The `dplyr` package

`dplyr`: (efficiently) split-apply-combine for data frames

**Verbs** 
a verb is a function that takes a data frame as it's first argument

- `filter`: select rows
- `arrange`: order rows
- `select`: select columns
- `rename`: rename columns
- `distinct`: find distinct rows
- `mutate`: add new variables
- `summarise`: summarize across a data set
- `sample_n`: sample from a data set 

## Data

In this part of the lecture we will work with the Danish federal budget proposal for 2016

```{r, message = FALSE, warning = FALSE}
library("readr")
library("dplyr")
gh.link = "https://raw.githubusercontent.com/"
user.repo = "sebastianbarfort/sds_summer/"
branch = "gh-pages/"
link = "data/finanslov_tidy.csv"
data.link = paste0(gh.link, user.repo, branch, link)
df = read_csv(data.link)
```

Some nice guy has already cleaned this data for you

## View the data

### Try yourself

```{r, eval = FALSE}
View(df)
glimpse(df)
summary(df)
head(df)
```

## Filtering data I

`filter` return rows with matching conditions.

```{r}
df.max.udgift = df %>% 
  filter(udgift == max(udgift)) %>% 
  select(paragraf, aar, udgift)
```

```{r, echo = FALSE}
knitr::kable(df.max.udgift)
```

## Filtering data II

```{r}
df.skat = df %>% 
  filter(paragraf == "Skatter og afgifter") %>%
  select(paragraf, aar, udgift) %>% 
  arrange(-udgift)
```
```{r, echo = FALSE}
knitr::kable(df.skat[1:5, ])
```

## Logical operators

![](figures/transform-logical.png)

## Creating new variables

`mutate` let's you add new variables to your data frame

```{r}
df.mutated = df %>%
  mutate(newVar = udgift/2) %>%
  select(newVar, udgift)
```

```{r, echo = FALSE}
knitr::kable(df.mutated[1:5, ])
```

## Sampling from a data frame

We can sample from a data frame using `sample_n` and `sample_frac`

```{r}
df.sample.n = df %>% 
  select(paragraf, aar, udgift) %>%
  sample_n(3)
```

```{r, echo = FALSE}
knitr::kable(df.sample.n)
```

## Grouped operations

So far, we have primarily learned how to manipulate data frames. 

The `dplyr` package becomes really powerful when we introduce the `group_by` function

`group_by` breaks down a dataset into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied "by group".

Use in conjunction with `mutate` (to add existing rows to your data frame) or `summarise` (to create a new data frame)

## Common `mutate`/`summarise` options

- `mean`: mean within groups
- `sum`: sum within groups
- `sd`: standard deviation within groups
- `max`: max within groups
- `n()`: number in each group
- `first`: first in group
- `last`: last in group
- `nth(n = 3)`: nth in group (3rd here)
- `tally`: count number in group

## Operating on groups I

Which ministry has the largest expenses?

```{r}
df.expense = df %>% 
  group_by(paragraf) %>% 
  summarise(sum.exp = sum(udgift, na.rm = TRUE)) %>% 
  arrange(-sum.exp)
```

```{r, echo = FALSE}
knitr::kable(df.expense[1:5, ])
```

## Operating on groups II

Add `sum.exp` to existing data frame

```{r}
df.2 = df %>% 
  group_by(paragraf) %>% 
  mutate(sum.exp = sum(udgift, na.rm = TRUE)) %>% 
  select(paragraf, udgift, sum.exp)
```

```{r, echo = FALSE}
knitr::kable(df.2[1:5, ])
```

## Operating on groups III

You can group by several variables

```{r}
df.expense.2 = df %>% 
  group_by(paragraf, aar) %>% 
  summarise(sum.exp = sum(udgift, na.rm = TRUE)) %>% 
  arrange(sum.exp)
```

```{r, echo = FALSE}
knitr::kable(df.expense.2[1:5, ])
```

## Operating on groups IV

Let's first calculate yearly expenses at the `paragraf` level and then calculate mean expenses over the years.


```{r}
df.expense.3 = df %>% 
  group_by(paragraf, aar) %>% 
  summarise(exp = sum(udgift, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(paragraf) %>%
  summarise(sum.exp = mean(exp, na.rm = TRUE))
```

##

```{r, echo = FALSE}
knitr::kable(df.expense.3[1:5, ])
```

## Merging data sets

\centering
![](figures/joins.png)

## Superhero example

```{r, echo = FALSE}
superheroes = c("    name, alignment, gender,         publisher",
    " Magneto,       bad,   male,            Marvel",
    "   Storm,      good, female,            Marvel",
    "Mystique,       bad, female,            Marvel",
    "  Batman,      good,   male,                DC",
    "   Joker,       bad,   male,                DC",
    "Catwoman,       bad, female,                DC",
    " Hellboy,      good,   male, Dark Horse Comics")

superheroes = read.csv(text = superheroes, strip.white = TRUE)
```

### Look at this dataset 

```{r, echo = FALSE}
knitr::kable(superheroes)
```

## Publishers

### And this

```{r, echo = FALSE}
publishers = c("publisher, yr_founded",
    "       DC,       1934",
    "   Marvel,       1939",
    "    Image,       1992")
publishers = read.csv(text = publishers, strip.white = TRUE)
```

```{r, echo = FALSE}
knitr::kable(publishers)
```

## Inner join

```{r}
ijsp = inner_join(superheroes, publishers)
```

```{r, echo = FALSE}
knitr::kable(ijsp)
```

## Left join

```{r}
ljsp = left_join(superheroes, publishers)
```

```{r, echo = FALSE}
knitr::kable(ljsp)
```

## Merging different names

```{r, message = TRUE}
superheroes = superheroes %>% 
  mutate(seblikes = (publisher == "Marvel"))
publishers = publishers %>% 
  mutate(seb = (publisher == "Marvel"))
ij2 = inner_join(superheroes,publishers)
```

## 

```{r, echo = FALSE}
knitr::kable(ij2)
```

## Merging by different names

```{r}
ij2 = inner_join(superheroes, publishers,
                    by=c("publisher"="publisher",
                            "seblikes"="seb"))
```

## 

```{r, echo = FALSE}
knitr::kable(ij2)
```

## Full join

```{r}
fj = superheroes %>%
  full_join(publishers)
```

```{r, echo = FALSE}
knitr::kable(fj[, -c(5, 7)])
```

---

\LARGE Functions and Iteration

## Introduction

Perhaps most important skill for being effective when working with data: write functions.

### Advantages

1. You drastically reduce risk of making mistakes
2. When something exogenous changes, you only need to update code in one place
3. You can give your function an intuitive name that makes your code easier to read

You should write functions to \alert{increase your productivity}.

## 

\centering
![](figures/the_general_problem.png)

## Template

```{r, eval = FALSE}
my_function = function(input1, input2, ..., inputN)
  {
  # define 'output' using input1,...,inputN
  return(output)
  }
```

## Example 

```{r}
add_numbers = function(x, y){
  z = x + y
  return(z)
}

add_numbers(2, 4)
add_numbers(2, 6)
```

## Errors

### Now what

```{r, error = TRUE}
add_numbers(2, "y")
```

## Conditional Execution

```{r}
add_numbers = function(x, y){
  if ( !is.numeric(x) || !is.numeric(y)) {
    warning("either 'x' or 'y' is not numeric")
    return(NA)
  }
  else {
    z = x + y
    return(z)
  }
}
```

## Testing

```{r, warning = TRUE}
add_numbers(2, 4)
add_numbers(2, "y")
```

## Iteration

One important skill for being an effective data analyst was being able to \alert{write functions}. A second is \alert{iteration}. 

Iteration helps you when you need to do the same thing to multiple inputs. For example, repeating the same function on lots of inputs. 

Two iteration paradigms

1. Imperative programming (`for` loops, etc.) 
2. Functional programming 

## Data

Imagine that we have this data frame, called `df`

```{r, echo = FALSE}
df = data.frame(
  a = rnorm(5),
  b = rnorm(5),
  c = runif(5),
  d = rchisq(5, 1)
)
```

```{r, echo = FALSE}
knitr::kable(df)
```

And assume that we want to compute the mean of each column

## The `for` loop

We could iterate through each column, compute the mean and output the results

```{r}
output = vector()
for (i in 1:ncol(df)){
  output[[i]] = mean(df[, i], na.rm = TRUE)
}
output
```

---

## Your turn

\centering
We will do Exercise 4.5.1 in Imai (2016). 

## Read data

### `intrade`

```{r}
library("readr")
gh.link = "https://raw.githubusercontent.com/"
user.repo = "kosukeimai/qss/"
branch = "master/"
link = "PREDICTION/intrade08.csv"
data.link = paste0(gh.link, user.repo, branch, link)
intrade.08 = read_csv(data.link)
```

```{r}
link = "PREDICTION/intrade12.csv"
data.link = paste0(gh.link, user.repo, branch, link)
intrade.12 = read_csv(data.link)
```

##

 Name                Description
 ------------------- ---------------------------------------------------------
 `day`               Date of the session 
 `statename`         Full name of each state 
 `state`             Abbreviation of each state 
 `PriceD`            Predicted vote share of D Nominee's market
 `PriceR`            Predicted vote share of R Nominee's market 
 `VolumeD`           Total session trades of D Nominee's market
 `VolumeR`           Total session trades of R Nominee's market 

## 

### `pres`

```{r}
link = "PREDICTION/pres08.csv"
data.link = paste0(gh.link, user.repo, branch, link)
pres.08 = read_csv(data.link)
```

```{r}
link = "PREDICTION/pres12.csv"
data.link = paste0(gh.link, user.repo, branch, link)
pres.12 = read_csv(data.link)
```

##

 Name                 Description
 -------------------- ---------------------------------------------------------
 `state.name`         Full name of state (only in `pres2008`)
 `state`              Two letter state abbreviation
 `Obama`              Vote percentage for Obama
 `McCain`             Vote percentage for McCain
 `EV`                 Number of electoral college votes for this state

## 

### `polls`

```{r}
link = "PREDICTION/polls08.csv"
data.link = paste0(gh.link, user.repo, branch, link)
polls.08 = read_csv(data.link)
```

```{r}
link = "PREDICTION/polls12.csv"
data.link = paste0(gh.link, user.repo, branch, link)
polls.12 = read_csv(data.link)
```

## 

 Name                 Description
 -------------------- ---------------------------------------------------------
 `state`              Abbreviated name of state in which poll was conducted 
 `Obama`              Predicted support for Obama (percentage)
 `Romney`             Predicted support for Romney (percentage) 
 `Pollster`           Name of organization conducting poll 
 `middate`            Middle of the period when poll was conducted 


## Functional Programming I

`for` loops emphasize the objects instead of the functions

```{r, eval = FALSE}
output = vector()
for (i in 1:ncol(df)){
  output[[i]] = median(df[, i], na.rm = TRUE)
}
```

```{r, eval = FALSE}
output = vector()
for (i in 1:ncol(df)){
  output[[i]] = mean(df[, i], na.rm = TRUE)
}
```

## Functional programming II

```{r}
library("purrr")
map_dbl(df, mean)
map_dbl(df, median)
```

## Using you own function

```{r}
my_function = function(df){
  my.mean = mean(df, na.rm = TRUE)
  my.string = paste("mean is", 
                    round(my.mean, 2), 
                    sep = ":")
  return(my.string)
}
```

```{r}
map_chr(df, my_function)
```

---

\LARGE String Processing

## Regular expressions

A \alert{regular expression} is a pattern that describes a specific set of strings with a common structure. It is heavily used for string matching / replacing in all programming languages, although specific syntax may differ a bit. 

Regular expressions typically specify characters (or character classes) to seek out, possibly with information about repeats and location within the string. This is accomplished with the help of metacharacters that have specific meaning: `$ * + . ? [ ] ^ { } | ( ) \`

They can be difficult 

##

\centering
![](figures/xkcdregex.jpg)

## Quantifiers

Quantifiers specify how many repetitions of the pattern

- `*`: matches at least 0 times
- `+`: matches at least 1 times
- `?`: matches at most 1 times
- `{n}`: matches exactly *n* times
- `{n,}`: matches at least *n* times
- `{n,m}`: matches between *n* and *m* times

## Example

```{r}
strings = c("a", "ab", "acb", "accb", 
            "acccb", "accccb")
grep("ac*b", strings, value = TRUE)
grep("ac+b", strings, value = TRUE)
grep("ac?b", strings, value = TRUE)
```

## 

```{r}
grep("ac{2}b", strings, value = TRUE)
grep("ac{2,}b", strings, value = TRUE)
grep("ac{2,3}b", strings, value = TRUE)
```

## Operators 

- `.`: matches any single character, as shown in the first example.
- `[...]`: a character list, matches any one of the characters inside the square brackets. We can also use - inside the brackets to specify a range of characters.
- `[^...]`: an inverted character list, similar to [...], but matches any characters except those inside the square brackets.
- `|`: an “or” operator, matches patterns on either side of the |.
- `\`: suppress the special meaning of metacharacters in regular expression
- `^`: matches the start of the string.

## Example 

```{r}
strings = c("^ab", "ab", "abc", "abd", "abe", "ab 12")
grep("ab.", strings, value = TRUE)
grep("ab[c-e]", strings, value = TRUE)
grep("ab[^c]", strings, value = TRUE)
```

## 
```{r}
grep("^ab", strings, value = TRUE)
grep("\\^ab", strings, value = TRUE)
grep("abc|abd", strings, value = TRUE)
```

## Character classes

Character classes allows to specify entire classes of characters, such as numbers, letters, etc. 

- `[:digit:]` or `\d`: digits, 0 1 2 3 4 5 6 7 8 9, equivalent to `[0-9]`.
- `\D`: non-digits, equivalent to `[^0-9]`.
- `[:lower:]`: lower-case letters, equivalent to `[a-z]`.
- `[:upper:]`: upper-case letters, equivalent to `[A-Z]`.
- `[:alpha:]`: alphabetic characters, equivalent to `[[:lower:][:upper:]]` or `[A-z]`.
- `[:alnum:]`: alphanumeric characters, equivalent to `[[:alpha:][:digit:]]` or `[A-z0-9]`.
- `\w`: word characters, equivalent to `[[:alnum:]_]` or `[A-z0-9_]`.
- `\W`: not word, equivalent to `[^A-z0-9_]`.

##

- `[:blank:]`: blank characters, i.e. space and tab.
- `[:space:]`: space characters: tab, newline, vertical tab, form feed, carriage return, space.
- `\s`: space, ` `.
- `\S`: not space.
- `[:punct:]`: punctuation characters, ! " # $ % & ’ ( ) * + , - . / : ; < = > ? @ [  ] ^ _ ` { | } ~.

## The `stringr` package

The most consistent way of doing string manipulation in `R` is by using the `stringr` package. 

```{r}
library("stringr")
```

All functions in `stringr` start with `str_`.

All functions are pipeable! 

## Useful functions

- `str_length`: length of string 
- `str_c`: combine string
- `str_sub`: subset string
- `str_to_lower`: string to lower cases

## Matching with regular expressions

### Detect matches

```{r}
x = c("apple", "banana", "pear", "213")
x %>% str_detect("e")
x %>% str_detect("[0-9]")
x %>% str_detect("e.r")
```

## 

### Extract matches

```{r}
x %>% str_extract("apple|[0-9]*")
x %>% str_extract("a.*")
```

##

### If the string contains more than more element

```{r}
xx = c("apple 123", "banana", "pear", "213")
xx %>% str_extract("apple|[0-9]*")
xx %>% str_extract("a.*")
```

##

```{r}
xx %>% str_extract_all("apple|[0-9].")
```

## Replacing

### Replacing

```{r}
xx %>% str_replace("[0-9]", "\\?")
xx %>% str_replace_all("[0-9]", "\\?")
xx %>% str_replace_all(c("1" = "one", "2" = "x"))
```

## Split vector

### Splitting

```{r}
xx %>% str_split("a")
```

##

```{r}
xx %>% str_split("a", n = 2)
```



